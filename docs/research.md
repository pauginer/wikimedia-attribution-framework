# Research and resources

This page brings together the research materials that provide the empirical foundation for the guidance offered Wikimedia's attribution framework. As our work progresses, we'll continue to add new findings and resources to support a clearer, evidence-based understanding of attribution across platforms.

## Relevant studies

### Quantitative Study on Attribution: Search and AI assistants — November 2025

**Research lead**: Mike Raish, Lead Design Researcher at the Wikimedia Foundation
<!-- TODO Add link to full report !-->

#### Summary of the findings

In order to begin building an empirical basis for the Attribution Framework, we compared 6 individual attribution signals across two contexts—Search Engine Results Page (SERP) and LLM chatbots—in a 1,186-participant, survey-based experimental study. The goal of the study was to understand the effect that individual signals might have on users' “trust” in both the information presented and Wikipedia as a source. While most signals showed similar overall performance, users behaved quite differently in the two contexts: trust in LLM chat responses was noticeably shaped by the presence of attribution signals, especially when participants were more engaged with the content.

In contrast, trust in search engine results and sources was much less dependent on the presence of attribution. In this context, participants' pre-existing beliefs and browsing habits had stronger influence than the specific signals shown, and differences between signals were subtle. Overall, attribution cues played a clearer and more measurable role in LLM chatbots, whereas their impact in SERP environments was harder to detect.

<!-- TODO Add section about #### ChatGPT plugin study findings !-->